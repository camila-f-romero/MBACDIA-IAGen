{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj5nqPu1HfVX",
        "outputId": "de72df2c-6e26-4c5d-96da-7691ee996a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Instalações concluídas.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# === CÉLULA 1: Instalações ===\n",
        "# ==========================================\n",
        "!pip install --quiet --upgrade langchain langchain-openai langchain-community faiss-cpu PyPDF2 tiktoken \"unstructured[pdf]\" pdfminer.six pdf2image pillow streamlit \"aiofiles<24.0\" pytesseract pyngrok\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq poppler-utils tesseract-ocr tesseract-ocr-por\n",
        "\n",
        "print(\"Instalações concluídas.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# === CÉLULA 2: Imports Essenciais ===\n",
        "# ==========================================\n",
        "import os\n",
        "import streamlit as st\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "import numpy as np\n",
        "import faiss\n",
        "import tiktoken\n",
        "import traceback # Para imprimir erros detalhados\n",
        "\n",
        "# LangChain e relacionados\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# PDF e OCR\n",
        "from PyPDF2 import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Ngrok (para teste no Colab)\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"Imports concluídos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoYOMoSPH-U6",
        "outputId": "d52b98f0-8d1c-4047-d9da-5781158520d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports concluídos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "X-XW1NYERdbF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 3: Configuração API Key, Repositório GitHub e Caminhos ===\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    chave_teste = os.environ[\"OPENAI_API_KEY\"]\n",
        "    print(f\"✅ Chave OpenAI carregada com sucesso: {chave_teste[:5]}...{chave_teste[-4:]}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ao carregar chave OpenAI: {e}\")\n",
        "\n",
        "# --- Carregar GitHub PAT do Userdata ---\n",
        "try:\n",
        "    GITHUB_PAT = userdata.get('GITHUB_PAT')\n",
        "    if not GITHUB_PAT:\n",
        "        raise ValueError(\"Secret GITHUB_PAT está vazio ou não foi encontrado.\")\n",
        "    print(\"✅ GitHub PAT carregado do userdata.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ao carregar GITHUB_PAT do userdata: {e}\")\n",
        "    print(\"   Certifique-se de criar um secret chamado 'GITHUB_PAT' com seu Personal Access Token.\")\n",
        "\n",
        "    raise e # Parar execução se não conseguir carregar o PAT\n",
        "\n",
        "# --- CONFIGURAÇÃO DO GITHUB ---\n",
        "# Monta a URL com o PAT para autenticação\n",
        "REPO_OWNER = \"camila-f-romero\"\n",
        "REPO_NAME = \"MBACDIA-IAGen\"\n",
        "REPO_URL_COM_PAT = f\"https://{GITHUB_PAT}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "NOME_REPO_LOCAL = REPO_NAME\n",
        "NOME_PASTA_PDFS_NO_REPO = \"arquivos-projeto\"\n",
        "\n",
        "# --- Clonar/Atualizar Repositório ---\n",
        "DIRETORIO_ATUAL = os.getcwd()\n",
        "print(f\"Diretório de trabalho atual: {DIRETORIO_ATUAL}\")\n",
        "CAMINHO_REPO_LOCAL_ABS = os.path.join(DIRETORIO_ATUAL, NOME_REPO_LOCAL)\n",
        "print(f\"Caminho absoluto esperado para o repositório local: {CAMINHO_REPO_LOCAL_ABS}\")\n",
        "\n",
        "if not os.path.exists(CAMINHO_REPO_LOCAL_ABS):\n",
        "    print(f\"Clonando repositório (usando PAT) para '{CAMINHO_REPO_LOCAL_ABS}'...\")\n",
        "    # Usa a URL com o PAT. Não precisa mais de GIT_TERMINAL_PROMPT=0 ou -c credential.helper=\n",
        "    ret_code = os.system(f\"git clone {REPO_URL_COM_PAT} '{CAMINHO_REPO_LOCAL_ABS}'\")\n",
        "    if ret_code == 0:\n",
        "        print(\"✅ Repositório clonado com sucesso.\")\n",
        "    else:\n",
        "        print(f\"❌ Falha ao clonar repositório (Código de retorno: {ret_code}). Verifique o PAT e a URL.\")\n",
        "        # Limpa o PAT da memória por segurança\n",
        "        GITHUB_PAT = None\n",
        "        raise RuntimeError(\"Falha no Git Clone com PAT\")\n",
        "else:\n",
        "    print(f\"Repositório '{NOME_REPO_LOCAL}' já existe em '{CAMINHO_REPO_LOCAL_ABS}'.\")\n",
        "    print(\"Verificando atualizações no repositório (usando PAT)...\")\n",
        "\n",
        "    ret_code = os.system(f\"cd '{CAMINHO_REPO_LOCAL_ABS}' && git pull\")\n",
        "    if ret_code == 0:\n",
        "         print(\"✅ Repositório atualizado com sucesso.\")\n",
        "    else:\n",
        "         print(f\"⚠️ Falha ao atualizar repositório com 'git pull' (Código: {ret_code}).\")\n",
        "\n",
        "# Limpa o PAT da memória após o uso inicial por segurança\n",
        "GITHUB_PAT = None\n",
        "\n",
        "# --- Define o Caminho para a Pasta de PDFs ---\n",
        "CAMINHO_PASTA_PDFS = os.path.join(CAMINHO_REPO_LOCAL_ABS, NOME_PASTA_PDFS_NO_REPO)\n",
        "print(f\"Caminho completo esperado para a pasta de PDFs: {CAMINHO_PASTA_PDFS}\")\n",
        "\n",
        "# --- Verificação Final ---\n",
        "print(f\"\\nVerificando novamente a existência de '{CAMINHO_REPO_LOCAL_ABS}'...\")\n",
        "if os.path.exists(CAMINHO_REPO_LOCAL_ABS):\n",
        "    print(f\"✅ Diretório do repositório '{NOME_REPO_LOCAL}' encontrado.\")\n",
        "    try:\n",
        "        print(f\"   Conteúdo encontrado na raiz do repositório clonado:\", os.listdir(CAMINHO_REPO_LOCAL_ABS))\n",
        "        print(f\"\\nVerificando a existência da pasta de PDFs '{CAMINHO_PASTA_PDFS}'...\")\n",
        "        if os.path.exists(CAMINHO_PASTA_PDFS):\n",
        "            print(f\"✅ Pasta de PDFs encontrada em: '{CAMINHO_PASTA_PDFS}'\")\n",
        "        else:\n",
        "            print(f\"❌ ATENÇÃO: A pasta de PDFs '{NOME_PASTA_PDFS_NO_REPO}' NÃO foi encontrada dentro de '{CAMINHO_REPO_LOCAL_ABS}'.\")\n",
        "            print(f\"   Verifique se o nome '{NOME_PASTA_PDFS_NO_REPO}' está correto e se a pasta existe no repositório GitHub.\")\n",
        "    except Exception as list_err:\n",
        "        print(f\"❌ Erro ao listar conteúdo de '{CAMINHO_REPO_LOCAL_ABS}': {list_err}\")\n",
        "else:\n",
        "    print(f\"❌ Erro Crítico: O diretório do repositório '{NOME_REPO_LOCAL}' não foi encontrado após a tentativa de clonagem/atualização.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-57foDR_RmgR",
        "outputId": "e6ba4736-83d3-43dc-8cfc-87c20fe8acd0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chave OpenAI carregada com sucesso: sk-pr...kRwA\n",
            "✅ GitHub PAT carregado do userdata.\n",
            "Diretório de trabalho atual: /content\n",
            "Caminho absoluto esperado para o repositório local: /content/MBACDIA-IAGen\n",
            "Repositório 'MBACDIA-IAGen' já existe em '/content/MBACDIA-IAGen'.\n",
            "Verificando atualizações no repositório (usando PAT)...\n",
            "✅ Repositório atualizado com sucesso.\n",
            "Caminho completo esperado para a pasta de PDFs: /content/MBACDIA-IAGen/arquivos-projeto\n",
            "\n",
            "Verificando novamente a existência de '/content/MBACDIA-IAGen'...\n",
            "✅ Diretório do repositório 'MBACDIA-IAGen' encontrado.\n",
            "   Conteúdo encontrado na raiz do repositório clonado: ['.git', 'faiss_index_anpd_acts', 'arquivos-projeto']\n",
            "\n",
            "Verificando a existência da pasta de PDFs '/content/MBACDIA-IAGen/arquivos-projeto'...\n",
            "✅ Pasta de PDFs encontrada em: '/content/MBACDIA-IAGen/arquivos-projeto'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 4: Funções Auxiliares (Extração de Texto PDF/OCR) ===\n",
        "\n",
        "# Função básica de extração com PyPDF2\n",
        "def extrair_texto_pypdf2(pdf_path):\n",
        "    texto = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            leitor = PdfReader(f)\n",
        "            if leitor.is_encrypted:\n",
        "                try:\n",
        "                    leitor.decrypt(\"\") # Tenta descriptografar com senha vazia\n",
        "                except Exception as decrypt_err:\n",
        "                    print(f\"  -> Aviso: PDF criptografado e falha ao descriptografar '{os.path.basename(pdf_path)}': {decrypt_err}\")\n",
        "                    # return \"\" # Ou pode tentar extrair mesmo assim se a criptografia for leve\n",
        "\n",
        "            for pagina in leitor.pages:\n",
        "                try:\n",
        "                    texto_pagina = pagina.extract_text()\n",
        "                    if texto_pagina:\n",
        "                        texto += texto_pagina + \"\\n\" # Adicionar nova linha entre páginas\n",
        "                except Exception as page_err:\n",
        "                     print(f\"  -> Erro ao extrair texto da página em '{os.path.basename(pdf_path)}': {page_err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Erro PyPDF2 em '{os.path.basename(pdf_path)}': {e}\")\n",
        "    return texto.strip()\n",
        "\n",
        "# Função de extração com OCR (Tesseract via pdf2image)\n",
        "def extrair_texto_ocr(pdf_path):\n",
        "    texto_total = \"\"\n",
        "    print(f\"  -> Tentando OCR em: {os.path.basename(pdf_path)}\")\n",
        "    try:\n",
        "        imagens = convert_from_path(\n",
        "            pdf_path,\n",
        "            dpi=300, # Boa resolução para OCR\n",
        "            poppler_path=\"/usr/bin\",\n",
        "            thread_count=2 # Ajuste se necessário\n",
        "        )\n",
        "        if not imagens:\n",
        "             print(f\"  -> Aviso: pdf2image não retornou imagens para OCR em '{os.path.basename(pdf_path)}'.\")\n",
        "             return \"\"\n",
        "\n",
        "        for i, img in enumerate(imagens):\n",
        "            try:\n",
        "                texto_pagina = pytesseract.image_to_string(img, lang='por', config='--psm 6') # Tenta detectar layout\n",
        "                texto_total += f\"\\n--- Página OCR {i+1} ---\\n{texto_pagina}\"\n",
        "            except Exception as ocr_err:\n",
        "                 print(f\"    -> Erro OCR na página {i+1}: {ocr_err}\")\n",
        "        print(f\"  -> OCR concluído para: {os.path.basename(pdf_path)}\")\n",
        "        return texto_total.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Falha GERAL no OCR para '{os.path.basename(pdf_path)}': {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Função inteligente que tenta PyPDF2 e usa OCR como fallback\n",
        "def extrair_texto_inteligente(pdf_path, limiar_ocr=150):\n",
        "    \"\"\"\n",
        "    Tenta extrair texto com PyPDF2. Se o texto for muito curto (abaixo do limiar),\n",
        "    tenta usar OCR. Retorna o texto mais longo obtido.\n",
        "    \"\"\"\n",
        "    print(f\"Processando: {os.path.basename(pdf_path)}\")\n",
        "    texto_normal = \"\"\n",
        "    texto_ocr = \"\"\n",
        "\n",
        "    texto_normal = extrair_texto_pypdf2(pdf_path)\n",
        "\n",
        "    if len(texto_normal) < limiar_ocr:\n",
        "        print(f\"  -> Texto PyPDF2 curto ({len(texto_normal)} chars). Ativando OCR...\")\n",
        "        texto_ocr = extrair_texto_ocr(pdf_path)\n",
        "\n",
        "        if len(texto_ocr) > len(texto_normal):\n",
        "             print(f\"  -> Usando resultado do OCR ({len(texto_ocr)} chars).\")\n",
        "             return texto_ocr\n",
        "        else:\n",
        "             print(f\"  -> Resultado do OCR não foi melhor ({len(texto_ocr)} chars). Mantendo resultado PyPDF2.\")\n",
        "             return texto_normal\n",
        "    else:\n",
        "        # print(f\"  -> Extraído via PyPDF2 ({len(texto_normal)} chars).\")\n",
        "        return texto_normal\n",
        "\n",
        "print(\"Funções auxiliares de extração definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ1mVQi6XkXh",
        "outputId": "48bc09e2-047f-47bf-de55-bfb9ff26dfb4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funções auxiliares de extração definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 5: Carregamento dos Documentos ===\n",
        "\n",
        "documentos_carregados = [] # Lista para guardar os Documentos LangChain\n",
        "\n",
        "print(\"\\n--- Iniciando Carregamento de Documentos ---\")\n",
        "# Verifica se o CAMINHO_PASTA_PDFS realmente existe e não está vazio antes de prosseguir\n",
        "if not os.path.exists(CAMINHO_PASTA_PDFS) or not os.listdir(CAMINHO_PASTA_PDFS):\n",
        "     print(f\"🚨 Erro Crítico: Pasta de PDFs '{CAMINHO_PASTA_PDFS}' não encontrada ou vazia. Verifique a Célula 3 e o repositório.\")\n",
        "     # Define a lista como vazia para as próximas células saberem que falhou\n",
        "     documentos_carregados = []\n",
        "else:\n",
        "    # Lista os arquivos PDF encontrados para processamento\n",
        "    arquivos_pdf_encontrados = [f for f in os.listdir(CAMINHO_PASTA_PDFS) if f.lower().endswith('.pdf')]\n",
        "    print(f\"Encontrados {len(arquivos_pdf_encontrados)} arquivo(s) PDF em '{CAMINHO_PASTA_PDFS}'.\")\n",
        "\n",
        "    # Tenta carregar usando a extração inteligente para cada arquivo\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf_encontrados:\n",
        "        caminho_completo = os.path.join(CAMINHO_PASTA_PDFS, nome_arquivo)\n",
        "        texto_extraido = extrair_texto_inteligente(caminho_completo, limiar_ocr=150)\n",
        "        if texto_extraido:\n",
        "            doc = Document(page_content=texto_extraido, metadata={'source': caminho_completo})\n",
        "            documentos_carregados.append(doc)\n",
        "            print(f\"  -> OK: {nome_arquivo} ({len(texto_extraido)} chars)\") # Confirmação\n",
        "        else:\n",
        "             print(f\"  -> Falha/Vazio: {nome_arquivo}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n✅ Carregamento concluído: {len(documentos_carregados)} documentos processados e carregados.\")\n",
        "\n",
        "# Verificação final\n",
        "if documentos_carregados:\n",
        "    print(f\"\\n--- Processamento Finalizado ---\")\n",
        "    print(f\"Total de Documentos LangChain prontos para divisão: {len(documentos_carregados)}\")\n",
        "else:\n",
        "    print(\"\\n🚨 ATENÇÃO: Nenhum documento foi carregado com sucesso. Verifique os logs acima.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFMGnDviYkjI",
        "outputId": "f79f343b-41a9-4578-9377-cc188aaf7ff9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Carregamento de Documentos ---\n",
            "Encontrados 9 arquivo(s) PDF em '/content/MBACDIA-IAGen/arquivos-projeto'.\n",
            "Processando: compress ocr mou-anpd-aepd-pt_compressed.pdf\n",
            "  -> OK: compress ocr mou-anpd-aepd-pt_compressed.pdf (14473 chars)\n",
            "Processando: compress ocr cade act-tarjado-compactado_compressed.pdf\n",
            "  -> OK: compress ocr cade act-tarjado-compactado_compressed.pdf (35445 chars)\n",
            "Processando: compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf\n",
            "  -> OK: compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf (32508 chars)\n",
            "Processando: compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf\n",
            "  -> OK: compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf (27441 chars)\n",
            "Processando: compress ocr CGU Acordo_de_cooperacao_ANPD (1)_compressed.pdf\n",
            "  -> OK: compress ocr CGU Acordo_de_cooperacao_ANPD (1)_compressed.pdf (36755 chars)\n",
            "Processando: compress ocr EXTRATO_CARTA_DE_ACEITE_DOU_compressed.pdf\n",
            "  -> OK: compress ocr EXTRATO_CARTA_DE_ACEITE_DOU_compressed.pdf (1038 chars)\n",
            "Processando: compress ocr act-senacon_ocultado (1)_compressed.pdf\n",
            "  -> OK: compress ocr act-senacon_ocultado (1)_compressed.pdf (17794 chars)\n",
            "Processando: compress ocr ans ANPD_ACT_assinado_2024 (1)_compressed.pdf\n",
            "  -> OK: compress ocr ans ANPD_ACT_assinado_2024 (1)_compressed.pdf (21826 chars)\n",
            "Processando: compress ocr act-nicbr-publico_compressed.pdf\n",
            "  -> OK: compress ocr act-nicbr-publico_compressed.pdf (29145 chars)\n",
            "\n",
            "✅ Carregamento concluído: 9 documentos processados e carregados.\n",
            "\n",
            "--- Processamento Finalizado ---\n",
            "Total de Documentos LangChain prontos para divisão: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 6: Divisão dos Documentos em Chunks ===\n",
        "\n",
        "chunks = [] # Inicializa a lista de chunks\n",
        "\n",
        "if documentos_carregados:\n",
        "    print(\"\\n--- Iniciando Divisão em Chunks ---\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,        # Tamanho do chunk\n",
        "        chunk_overlap=150,      # Sobreposição\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # Separadores comuns\n",
        "        keep_separator=False,\n",
        "        add_start_index=True,   # Adiciona metadado com índice inicial\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_documents(documentos_carregados)\n",
        "    print(f\"✅ Documentos divididos em {len(chunks)} chunks.\")\n",
        "\n",
        "\n",
        "    tamanhos = [len(c.page_content) for c in chunks]\n",
        "    print(f\"   Tamanhos (Min/Médio/Max): {min(tamanhos)} / {int(np.mean(tamanhos))} / {max(tamanhos)}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️ Não há documentos carregados para dividir. Pule esta célula ou corrija a Célula 5.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eLbuYd9Yskf",
        "outputId": "a5988983-99ac-4326-dec3-310aa7c64559"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Divisão em Chunks ---\n",
            "✅ Documentos divididos em 256 chunks.\n",
            "   Tamanhos (Min/Médio/Max): 135 / 945 / 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 7: Criação do Banco de Vetores (FAISS) ===\n",
        "\n",
        "banco_vetores = None # Inicializa a variável\n",
        "\n",
        "if chunks: # Só prossiga se houver chunks\n",
        "    print(\"\\n--- Iniciando Criação do Banco de Vetores FAISS ---\")\n",
        "    try:\n",
        "        embeddings = OpenAIEmbeddings() # Modelo padrão: text-embedding-ada-002\n",
        "\n",
        "        print(f\"Gerando embeddings e criando índice FAISS para {len(chunks)} chunks...\")\n",
        "        banco_vetores = FAISS.from_documents( # Usa os chunks\n",
        "            documents=chunks,\n",
        "            embedding=embeddings\n",
        "        )\n",
        "        print(f\"✅ Banco de vetores FAISS criado com sucesso com {banco_vetores.index.ntotal} vetores.\")\n",
        "\n",
        "        # Opcional: Salvar o índice localmente\n",
        "        # try:\n",
        "        #    indice_path = \"meu_indice_faiss_colab\"\n",
        "        #    banco_vetores.save_local(indice_path)\n",
        "        #    print(f\"✅ Índice FAISS salvo localmente em '{indice_path}'.\")\n",
        "        # except Exception as save_err:\n",
        "        #    print(f\"⚠️ Erro ao salvar índice FAISS: {save_err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao criar o banco de vetores FAISS: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"\\n⚠️ Não há chunks para criar o banco de vetores. Pule esta célula ou corrija a Célula 6.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBus-zvrYv3Z",
        "outputId": "261b4f89-8b37-49a6-d26e-2911d116004a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Criação do Banco de Vetores FAISS ---\n",
            "Gerando embeddings e criando índice FAISS para 256 chunks...\n",
            "✅ Banco de vetores FAISS criado com sucesso com 256 vetores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 7.5: Salvar Índice FAISS ===\n",
        "if banco_vetores:\n",
        "    NOME_PASTA_INDICE = \"faiss_index_anpd_acts\"\n",
        "    try:\n",
        "        banco_vetores.save_local(NOME_PASTA_INDICE)\n",
        "        print(f\"✅ Índice FAISS salvo com sucesso na pasta '{NOME_PASTA_INDICE}'.\")\n",
        "        print(\"   Arquivos criados:\", os.listdir(NOME_PASTA_INDICE))\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao salvar índice FAISS localmente: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ Banco de vetores não existe, não é possível salvar o índice.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26QSl5rJZwTE",
        "outputId": "d4460d7f-9c6c-4cb7-cb32-1f5c899c5826"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Índice FAISS salvo com sucesso na pasta 'faiss_index_anpd_acts'.\n",
            "   Arquivos criados: ['index.faiss', 'index.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 8: Configuração e Teste da Chain RetrievalQA ===\n",
        "\n",
        "qa_chain_instance = None # Inicializa a variável\n",
        "\n",
        "if banco_vetores: # Só prossiga se o banco de vetores existir\n",
        "    print(\"\\n--- Configurando a Chain RetrievalQA ---\")\n",
        "    try:\n",
        "        # Configurar o Retriever\n",
        "        retriever = banco_vetores.as_retriever(\n",
        "            search_type=\"similarity\", # Busca por similaridade\n",
        "            search_kwargs={'k': 6}    # Retorna os 6 chunks mais relevantes\n",
        "        )\n",
        "        print(f\"Retriever configurado (k={retriever.search_kwargs.get('k', 'Padrão')}).\")\n",
        "\n",
        "        # Configurar o LLM\n",
        "        llm = ChatOpenAI(\n",
        "            model_name='gpt-3.5-turbo',\n",
        "            temperature=0.3\n",
        "        )\n",
        "        print(f\"LLM configurado: {llm.model_name} (Temperature={llm.temperature})\")\n",
        "\n",
        "        # Criar a Chain RetrievalQA\n",
        "        qa_chain_instance = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\", # Combina contexto e pergunta num único prompt\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True, # Retorna os chunks usados\n",
        "            chain_type_kwargs={\"prompt\": None} # Usar prompt padrão do Langchain para \"stuff\"\n",
        "        )\n",
        "        print(\"✅ Chain RetrievalQA criada com sucesso!\")\n",
        "\n",
        "        # --- Teste ---\n",
        "        print(\"\\n--- Testando a Chain ---\")\n",
        "        # Use uma pergunta relevante para os seus documentos ACTs\n",
        "        pergunta_teste = \"Qual o objeto do acordo de cooperação técnica entre ANPD e TSE?\"\n",
        "        # pergunta_teste = \"Quais as obrigações da ANPD no acordo com o CADE?\"\n",
        "        # pergunta_teste = \"Qual a vigência do acordo entre CGU e ANPD?\"\n",
        "\n",
        "        print(f\"\\nPergunta: {pergunta_teste}\")\n",
        "\n",
        "        try:\n",
        "             # Use .invoke para Langchain >= 0.1.0\n",
        "             resposta = qa_chain_instance.invoke({\"query\": pergunta_teste})\n",
        "             # Para versões mais antigas, pode ser necessário usar:\n",
        "             # resposta = qa_chain_instance({\"query\": pergunta_teste})\n",
        "\n",
        "             print(\"\\n--- Resposta Gerada ---\")\n",
        "             print(resposta.get('result', 'Nenhuma resposta encontrada.'))\n",
        "\n",
        "             print(\"\\n--- Documentos Fonte Utilizados ---\")\n",
        "             if resposta.get('source_documents'):\n",
        "                 fontes_usadas = set() # Para evitar listar a mesma fonte múltiplas vezes\n",
        "                 for i, doc in enumerate(resposta['source_documents']):\n",
        "                     source_file = os.path.basename(doc.metadata.get('source', 'N/A'))\n",
        "                     if source_file not in fontes_usadas:\n",
        "                          print(f\"- {source_file}\")\n",
        "                          fontes_usadas.add(source_file)\n",
        "                     # Opcional: mostrar trecho do chunk\n",
        "                     # print(f\"  Chunk (Início: {doc.metadata.get('start_index', '?')}): {doc.page_content[:150]}...\")\n",
        "                 if not fontes_usadas:\n",
        "                      print(\"Nenhum nome de arquivo encontrado nos metadados dos documentos fonte.\")\n",
        "             else:\n",
        "                 print(\"Nenhum documento fonte retornado pela chain.\")\n",
        "\n",
        "        except Exception as query_err:\n",
        "             print(f\"\\n❌ Erro ao executar a pergunta na chain: {query_err}\")\n",
        "             traceback.print_exc()\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao configurar a chain QA: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️ Banco de vetores não foi criado. Não é possível configurar ou testar a Chain QA.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- CONTEÚDO dos Documentos Fonte Recuperados ---\")\n",
        "if resposta.get('source_documents'):\n",
        "    for i, doc in enumerate(resposta['source_documents']):\n",
        "        print(f\"--- Fonte {i+1} ({os.path.basename(doc.metadata.get('source', 'N/A'))}) ---\")\n",
        "        print(doc.page_content) # Imprime o conteúdo completo do chunk\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"Nenhum documento fonte recuperado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivPFPu75Y1H5",
        "outputId": "d62834b3-d77f-4533-9814-6bcbd26eec5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configurando a Chain RetrievalQA ---\n",
            "Retriever configurado (k=6).\n",
            "LLM configurado: gpt-3.5-turbo (Temperature=0.3)\n",
            "✅ Chain RetrievalQA criada com sucesso!\n",
            "\n",
            "--- Testando a Chain ---\n",
            "\n",
            "Pergunta: Qual o objeto do acordo de cooperação técnica entre ANPD e TSE?\n",
            "\n",
            "--- Resposta Gerada ---\n",
            "O objeto do acordo de cooperação técnica entre a Autoridade Nacional de Proteção de Dados (ANPD) e o Tribunal Superior Eleitoral (TSE) é a realização de ações conjuntas para orientação e monitoramento da implementação da Lei Geral de Proteção de Dados (LGPD) no contexto eleitoral.\n",
            "\n",
            "--- Documentos Fonte Utilizados ---\n",
            "- compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf\n",
            "- compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf\n",
            "- compress ocr act-senacon_ocultado (1)_compressed.pdf\n",
            "- compress ocr cade act-tarjado-compactado_compressed.pdf\n",
            "\n",
            "--- CONTEÚDO dos Documentos Fonte Recuperados ---\n",
            "--- Fonte 1 (compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf) ---\n",
            "concessdo de medidas preventivas de competéncia do TSE; \n",
            "- Subsidiar a ANPD quanto ao conteúdo de qualquer material a ser desenvolvido em conjunto, inclusive a \n",
            "partir da orientação técnica quanto ao conteúdo e à interpretação da legislação eleitoral, suas diretrizes \n",
            "interpretativas e, ainda, por meio da indicação de fontes de pesquisa bibliográfica;\n",
            "m\"- Realizar, em conjunto com a ANPD, estudos, pesquisas e ações de capacitação relacionados ao objeto do \n",
            "presente ACT; \n",
            "V- Aprovar, em conjunto com a ANPD, os principios e critérios a serem utilizados para a elaboragdo de material \n",
            "orientativo em cumprimento ao objeto do presente Acordo; \n",
            "V- Elaborar, em conjunto com a ANPD, material orientativo referente a aplicagdo das disposi¢des da LGPD no \n",
            "contexto eleitoral; e \n",
            "VI- Informar a ANPD a respeito de reunides, encontros, workshops, visitas técnicas, cursos, palestras, \n",
            "conferéncias, semindrios, simpósios, congressos ou quaisquer eventos que possam contribuir na capacitagao,\n",
            "--------------------\n",
            "--- Fonte 2 (compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf) ---\n",
            "sentido de orientar acerca da importancia do tratamento de dados pessoais em conformidade com a LGPD durante campanhas \n",
            "politico-eleitorais; \n",
            "CONSIDERANDO a compatibilidade das finalidades institucionais dos Participes com o objeto deste Acordo de Cooperagdo Técnica e, \n",
            "ainda, o interesse comum na realizagdo das ações que especifica; \n",
            "CONSIDERANDO que a atuagdo articulada entre a ANPD e o TSE proporcionara maior seguranga juridica e efetividade nas ações \n",
            "relacionadas a aplicação da LGPD e a garantia dos direitos à privacidade e a proteção de dados no contexto eleitoral; \n",
            "CONSIDERANDO o disposto nos arts. 55-J, $ 42, e 55-K, paragrafo único, da Lei 13.709, de 14 de agosto de 2018; \n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERAGAO TECNICA, tendo em vista o que consta do Processo nº 00261.001067/2021-23 e em \n",
            "observancia, no que couber, as disposi¢cdes da Lei nº 8.666, de 21 de julho de 1993, mediante as clausulas e condigdes a seguir: \n",
            "1 CLAUSULA PRIMEIRA — DO OBJETO\n",
            "--------------------\n",
            "--- Fonte 3 (compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf) ---\n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERAGAO TECNICA, tendo em vista o que consta do Processo SUPER.GOV (ANPD) nº 00261.000130/2022-95 e em \n",
            "observancia, no que couber, as disposiges da Lei n28.666, de 21 de julho de 1993, mediante as cléusulas e condições a seguir: \n",
            "CLAUSULA PRIMEIRA - DO OBJETO \n",
            "O presente ACORDO DE COOPERAÇÃO TECNICA — ACT tem por objeto a realização de ações conjuntas de interesse mútuo, que possibilitarão a orientação e o \n",
            "monitoramento quanto à implementação da LGPD, pela administração pública estadual. \n",
            "Subcláusula única. O objetivo deste ACT estd alinhado com as diretrizes descritas na Lei nº 13.709, de 14 de agosto de 2018 — Lei Geral de Proteção de Dados \n",
            "Pessoais, assim como com o Decreto nº 47.774 de 03 de dezembro de 2019, que dispõe sobre a estrutura organica da Controladoria-Geral do Estado. \n",
            "CLAUSULA SEGUNDA - DO PLANO DE TRABALHO\n",
            "--------------------\n",
            "--- Fonte 4 (compress ocr act-senacon_ocultado (1)_compressed.pdf) ---\n",
            "mediante as seguintes clausulas e condigdes: \n",
            "CLÁUSULA PRIMEIRA - DO OBJETO \n",
            "O presente Acordo tem por objeto a cooperação técnica entre a ANPD e a SENACON, a ser \n",
            "executada na cidade de Brasília (DF), com vistas a promover ações conjuntas sobre assuntos \n",
            "de interesse recíproco, dentre as quais se incluem: \n",
            "a) Apoio institucional e intercâmbio de informações relativas às suas respectivas esferas de \n",
            "atuação; \n",
            "b) Compartilhamento de informações agregadas e de dados estatísticos quanto a \n",
            "reclamações de consumidores relacionadas à proteção de dados pessoais, em especial \n",
            "aquelas registradas no Sistema Nacional de Informações de Defesa do Consumidor — \n",
            "SINDEC e nas bases de dados do Consumidor.gov.br; \n",
            "c) Uniformização de entendimentos e coordenação de ações, inclusive no que tange ao \n",
            "endereçamento de reclamações de consumidores e à atuação no caso de incidentes de \n",
            "segurança envolvendo dados pessoais de consumidores;\n",
            "--------------------\n",
            "--- Fonte 5 (compress ocr cade act-tarjado-compactado_compressed.pdf) ---\n",
            "efetividadepara o alcance da proteção de dados quando da sua utilizagio abusiva por parte de agentes \n",
            "econdmicos; e \n",
            "CONSIDERANDO o disposto no inciso XI, do art. 10 da Lei n° 12.529, de 30 de novembro de 2011, e \n",
            "o previstos no art. 55-J da Lei n. 13.079, de 14 de agosto de 2018; \n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERACAO TECNICA, tendo em vista o que consta do \n",
            "Processo nº 08700.002088/2021-51 e em observancia as disposigdes da Lei nº 8666/1993, legislagio \n",
            "correlacionada às politicas publicas e suas alteragdes, mediante as cldusulas e condigdes a seguir: \n",
            "CLAUSULA PRIMEIRA - DO OBJETO E DO OBJETIVO \n",
            "O objeto do presente ACORDO DE COOPERACAO TECNICA tem como finalidade a instituição de \n",
            "cooperação técnica entre o CADE e a ANPD, para viabilizar ações a serem adotadas pelas partes, de \n",
            "forma conjunta e coordenada, quando da ocorréncia de situagdes que interseccionam ambas as esferas de \n",
            "competéncias.\n",
            "--------------------\n",
            "--- Fonte 6 (compress ocr act-senacon_ocultado (1)_compressed.pdf) ---\n",
            "CPF: — Cargo: Secretária Nacional do Consumidor \n",
            "2. Identificação do Objeto \n",
            "Título do Projeto: Acordo de Cooperação Técnica entre a \n",
            "Autoridade Nacional de Proteção de Dados — ANPD, da \n",
            "Presidência da República, e a Secretaria Nacional do Período de Execução \n",
            "Consumidor do Ministério da Justiça e Segurança Pública — \n",
            "Mmisp \n",
            "Inicio Término \n",
            "o X Processo nº 08012.000596/2021-53 Pata de 24 meses apés \n",
            "assinatura do \" a assinatura acordo \n",
            "Objeto do Projeto: promoção de ações conjuntas nas áreas de proteção de dados pessoais e defesa \n",
            "do consumidor, incluindo intercâmbio de informações, uniformização de entendimentos, \n",
            "cooperação quanto a ações de fiscalização, desenvolvimento de ações de educação, formação e \n",
            "capacitação e elaboração de estudos e pesquisas. \n",
            "3. Diagnóstico, abrangência e justificativa \n",
            "A ANPD foi instituída pela Lei nº 13.709/2018 (LGPD), com competência para zelar pela \n",
            "proteção de dados pessoais e para fiscalizar e aplicar sanções em caso de tratamento de\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# === CÉLULA 9: Criar Arquivo da Aplicação (app.py) ===\n",
        "# ========================================================\n",
        "\n",
        "FAISS_INDEX_PATH_APP = \"faiss_index_anpd_acts\"\n",
        "\n",
        "OPENAI_SECRET_NAME_APP = \"OPENAI_API_KEY\"\n",
        "\n",
        "# Ajuste os parâmetros do LLM e Retriever para o App Streamlit.\n",
        "K_RETRIEVER_APP = 4\n",
        "LLM_MODEL_APP = 'gpt-4o-mini'\n",
        "LLM_TEMP_APP = 0.3\n",
        "\n",
        "# Personalize os textos da interface do usuário.\n",
        "APP_TITLE = \"🖊📑 Chatbot Consulta ACTs ANPD\"\n",
        "APP_HEADER = \"Consulte informações sobre Acordos de Cooperação Técnica da ANPD\"\n",
        "APP_INPUT_LABEL = \"Digite sua pergunta sobre os ACTs:\"\n",
        "APP_BUTTON_TEXT = \"Buscar Resposta\"\n",
        "\n",
        "\n",
        "# Cria o arquivo app.py com o código do Streamlit\n",
        "print(f\"\\n--- Criando arquivo app.py ---\")\n",
        "# Usamos uma string multi-linha normal e formatamos as variáveis do NOTEBOOK nela.\n",
        "# As f-strings que devem ser interpretadas pelo app.py em runtime precisam ter\n",
        "# suas chaves escapadas com chaves duplas {{ variavel }}.\n",
        "writefile_content = f\"\"\"\n",
        "import streamlit as st\n",
        "import os\n",
        "import time # Para simular processamento\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "import traceback # Para mostrar erros no app\n",
        "\n",
        "# --- Configurações e Carregamento de Recursos (com cache) ---\n",
        "\n",
        "# Carregar Chave API (Prioriza st.secrets)\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    # Tenta carregar do secrets.toml (para deploy no Streamlit Cloud)\n",
        "    OPENAI_API_KEY = st.secrets[\"{OPENAI_SECRET_NAME_APP}\"]\n",
        "    print(\"OpenAI Key carregada do st.secrets\") # Log interno\n",
        "except (FileNotFoundError, KeyError):\n",
        "    print(\"Secret '{OPENAI_SECRET_NAME_APP}' não encontrado no st.secrets. Tentando variável de ambiente...\")\n",
        "    # Tenta carregar de variáveis de ambiente\n",
        "    OPENAI_API_KEY = os.environ.get('{OPENAI_SECRET_NAME_APP}')\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\"OpenAI Key carregada da variável de ambiente.\")\n",
        "    else:\n",
        "        st.error(\"Chave API da OpenAI ('{OPENAI_SECRET_NAME_APP}') não configurada! Configure em st.secrets ou variável de ambiente.\")\n",
        "        st.stop() # Para a execução se não tiver a chave\n",
        "\n",
        "# Define a variável de ambiente para Langchain usar\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Caminho para o índice FAISS salvo\n",
        "FAISS_INDEX_PATH = \"{FAISS_INDEX_PATH_APP}\"\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Carregando base de conhecimento (índice FAISS)...\")\n",
        "def load_faiss_index(index_path):\n",
        "    if not os.path.exists(index_path):\n",
        "         # CORREÇÃO: Escapar chaves ao redor de index_path\n",
        "         st.error(f\"Pasta do índice FAISS não encontrada em '{{index_path}}'. Verifique se a pasta existe no repositório junto com app.py.\")\n",
        "         st.stop()\n",
        "    try:\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        vector_store = FAISS.load_local(\n",
        "            index_path,\n",
        "            embeddings,\n",
        "            allow_dangerous_deserialization=True\n",
        "        )\n",
        "        return vector_store\n",
        "    except Exception as e:\n",
        "        # CORREÇÃO: Escapar chaves ao redor de e\n",
        "        st.error(f\"Erro ao carregar índice FAISS: {{e}}\")\n",
        "        st.error(traceback.format_exc())\n",
        "        st.stop()\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Preparando o assistente (chain QA)...\")\n",
        "def create_qa_chain(_vector_store):\n",
        "    try:\n",
        "        # Usa variáveis definidas no início do script app.py (não precisa escapar)\n",
        "        llm = ChatOpenAI(model_name='{LLM_MODEL_APP}', temperature={LLM_TEMP_APP})\n",
        "        retriever = _vector_store.as_retriever(search_kwargs={{'k': {K_RETRIEVER_APP}}})\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True\n",
        "        )\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "         # CORREÇÃO: Escapar chaves ao redor de e\n",
        "         st.error(f\"Erro ao criar a chain QA: {{e}}\")\n",
        "         st.error(traceback.format_exc())\n",
        "         st.stop()\n",
        "\n",
        "# --- Carregar Recursos ---\n",
        "vector_store_app = load_faiss_index(FAISS_INDEX_PATH)\n",
        "qa_chain_app = create_qa_chain(vector_store_app)\n",
        "st.success(\"Assistente pronto!\") # Mensagem de sucesso após carregar tudo\n",
        "\n",
        "# --- Interface do Usuário Streamlit ---\n",
        "st.title(\"{APP_TITLE}\")\n",
        "st.markdown(\"{APP_HEADER}\")\n",
        "st.divider()\n",
        "\n",
        "with st.form(\"input_form\"):\n",
        "    user_question = st.text_area(\"{APP_INPUT_LABEL}\", key=\"user_input\", height=100)\n",
        "    submitted = st.form_submit_button(\"{APP_BUTTON_TEXT}\")\n",
        "\n",
        "    if submitted:\n",
        "        if user_question:\n",
        "            with st.spinner(\"Buscando informações nos documentos...\"):\n",
        "                try:\n",
        "                    start_time = time.time()\n",
        "                    resposta = qa_chain_app.invoke({{\"query\": user_question}})\n",
        "                    end_time = time.time()\n",
        "\n",
        "                    st.markdown(\"### Resposta:\")\n",
        "                    st.info(resposta.get('result', \"Não foi possível obter uma resposta.\"))\n",
        "                    st.caption(f\"Tempo de resposta: {{end_time - start_time:.2f}} segundos\") # Escapar aqui também\n",
        "\n",
        "                    with st.expander(\"Ver Documentos Fonte Utilizados\"):\n",
        "                        if resposta.get('source_documents'):\n",
        "                            fontes_usadas = set()\n",
        "                            for doc in resposta['source_documents']:\n",
        "                                source_file = os.path.basename(doc.metadata.get('source', 'N/A'))\n",
        "                                if source_file not in fontes_usadas:\n",
        "                                    # Usar st.markdown para formatar como código\n",
        "                                    st.markdown(f\"- `{source_file}`\")\n",
        "                                    fontes_usadas.add(source_file)\n",
        "                            if not fontes_usadas:\n",
        "                                 st.write(\"Nenhuma fonte específica identificada nos metadados.\")\n",
        "                        else:\n",
        "                            st.write(\"Nenhum documento fonte foi retornado pela chain.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    # CORREÇÃO: Escapar chaves ao redor de e\n",
        "                    st.error(f\"Ocorreu um erro ao processar sua pergunta:\")\n",
        "                    st.exception(e) # Mostra o erro detalhado no app\n",
        "        else:\n",
        "            st.warning(\"Por favor, digite uma pergunta.\")\n",
        "\n",
        "st.divider()\n",
        "st.caption(\"MBA IA & Big Data - Projeto GenAI RAG - Camila Falchetto\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Salva o conteúdo no arquivo app.py\n",
        "try:\n",
        "  with open(\"app.py\", \"w\") as f:\n",
        "    f.write(writefile_content)\n",
        "  print(\"✅ Arquivo app.py criado/sobrescrito com sucesso.\")\n",
        "except Exception as e:\n",
        "  print(f\"❌ Erro ao escrever o arquivo app.py: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "louSiVFOcOpg",
        "outputId": "d93bc959-dc0e-461f-a686-3114ebd50db2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Criando arquivo app.py ---\n",
            "✅ Arquivo app.py criado/sobrescrito com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# === CÉLULA 10: Iniciar Streamlit em Background e Expor com Ngrok ===\n",
        "# ===================================================================\n",
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"--- Iniciando Streamlit em Background ---\")\n",
        "\n",
        "# Comando para rodar streamlit em background e salvar logs\n",
        "# nohup: evita que o processo morra se a conexão 'cair'\n",
        "# > streamlit_log.txt: redireciona a saída padrão para o arquivo\n",
        "# 2>&1: redireciona a saída de erro para o mesmo arquivo da saída padrão\n",
        "# &: executa em background\n",
        "streamlit_command = \"nohup streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > streamlit_log.txt 2>&1 &\"\n",
        "\n",
        "# Executa o comando para iniciar o Streamlit\n",
        "print(f\"Executando: {streamlit_command}\")\n",
        "os.system(streamlit_command)\n",
        "print(\"Comando para iniciar Streamlit enviado para background.\")\n",
        "print(\"Aguardando alguns segundos para o servidor Streamlit iniciar...\")\n",
        "time.sleep(10) # Pausa por 10 segundos (ajuste se necessário)\n",
        "\n",
        "# Verifica se o Streamlit parece estar rodando (opcional, checando log)\n",
        "print(\"\\nVerificando log do Streamlit (streamlit_log.txt)...\")\n",
        "!tail streamlit_log.txt # Mostra as últimas linhas do log\n",
        "\n",
        "print(\"\\n--- Configurando Ngrok ---\")\n",
        "\n",
        "NGROK_SECRET_NAME = 'NGROK_AUTHTOKEN'\n",
        "\n",
        "try:\n",
        "    ngrok_auth = userdata.get(NGROK_SECRET_NAME)\n",
        "    if not ngrok_auth:\n",
        "         raise ValueError(f\"Secret '{NGROK_SECRET_NAME}' não encontrado ou vazio.\")\n",
        "\n",
        "    # Mata processos ngrok anteriores se existirem\n",
        "    print(\"Tentando limpar processos ngrok antigos...\")\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Configura e conecta o ngrok\n",
        "    ngrok.set_auth_token(ngrok_auth)\n",
        "    print(\"Token Ngrok configurado.\")\n",
        "    # Expor a porta 8501\n",
        "    public_url = ngrok.connect(8501, proto='http')\n",
        "    print(\"\\n=======================================================================\")\n",
        "    print(f\"✅ Aplicação Streamlit deve estar rodando em background.\")\n",
        "    print(f\"   Acesso público temporário via: {public_url}\")\n",
        "    print(\"   (Este túnel permanecerá ativo enquanto esta célula Colab estiver ativa)\")\n",
        "    print(\"   Para VER os logs do Streamlit, execute: !cat streamlit_log.txt\")\n",
        "    print(\"   Para PARAR TUDO: Interrompa/Reinicie o ambiente de execução do Colab.\")\n",
        "    print(\"=======================================================================\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Erro ao configurar ou iniciar ngrok: {e}\")\n",
        "    print(f\"   Verifique se o token '{NGROK_SECRET_NAME}' está nos secrets do Colab.\")\n",
        "    print(f\"   Verifique também o log do Streamlit ('streamlit_log.txt') para erros.\")\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDeciCjscU5N",
        "outputId": "93df9735-636e-4cbd-99c0-0cce9b3aac7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Streamlit em Background ---\n",
            "Executando: nohup streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > streamlit_log.txt 2>&1 &\n",
            "Comando para iniciar Streamlit enviado para background.\n",
            "Aguardando alguns segundos para o servidor Streamlit iniciar...\n",
            "\n",
            "Verificando log do Streamlit (streamlit_log.txt)...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.72.62.226:8501\n",
            "\n",
            "\n",
            "--- Configurando Ngrok ---\n",
            "Tentando limpar processos ngrok antigos...\n",
            "Token Ngrok configurado.\n",
            "\n",
            "=======================================================================\n",
            "✅ Aplicação Streamlit deve estar rodando em background.\n",
            "   Acesso público temporário via: NgrokTunnel: \"https://9786-34-72-62-226.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "   (Este túnel permanecerá ativo enquanto esta célula Colab estiver ativa)\n",
            "   Para VER os logs do Streamlit, execute: !cat streamlit_log.txt\n",
            "   Para PARAR TUDO: Interrompa/Reinicie o ambiente de execução do Colab.\n",
            "=======================================================================\n"
          ]
        }
      ]
    }
  ]
}
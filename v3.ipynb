{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj5nqPu1HfVX",
        "outputId": "de72df2c-6e26-4c5d-96da-7691ee996a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Instala√ß√µes conclu√≠das.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# === C√âLULA 1: Instala√ß√µes ===\n",
        "# ==========================================\n",
        "!pip install --quiet --upgrade langchain langchain-openai langchain-community faiss-cpu PyPDF2 tiktoken \"unstructured[pdf]\" pdfminer.six pdf2image pillow streamlit \"aiofiles<24.0\" pytesseract pyngrok\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq poppler-utils tesseract-ocr tesseract-ocr-por\n",
        "\n",
        "print(\"Instala√ß√µes conclu√≠das.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# === C√âLULA 2: Imports Essenciais ===\n",
        "# ==========================================\n",
        "import os\n",
        "import streamlit as st\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "import numpy as np\n",
        "import faiss\n",
        "import tiktoken\n",
        "import traceback # Para imprimir erros detalhados\n",
        "\n",
        "# LangChain e relacionados\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# PDF e OCR\n",
        "from PyPDF2 import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Ngrok (para teste no Colab)\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"Imports conclu√≠dos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoYOMoSPH-U6",
        "outputId": "d52b98f0-8d1c-4047-d9da-5781158520d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports conclu√≠dos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "X-XW1NYERdbF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 3: Configura√ß√£o API Key, Reposit√≥rio GitHub e Caminhos ===\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    chave_teste = os.environ[\"OPENAI_API_KEY\"]\n",
        "    print(f\"‚úÖ Chave OpenAI carregada com sucesso: {chave_teste[:5]}...{chave_teste[-4:]}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao carregar chave OpenAI: {e}\")\n",
        "\n",
        "# --- Carregar GitHub PAT do Userdata ---\n",
        "try:\n",
        "    GITHUB_PAT = userdata.get('GITHUB_PAT')\n",
        "    if not GITHUB_PAT:\n",
        "        raise ValueError(\"Secret GITHUB_PAT est√° vazio ou n√£o foi encontrado.\")\n",
        "    print(\"‚úÖ GitHub PAT carregado do userdata.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao carregar GITHUB_PAT do userdata: {e}\")\n",
        "    print(\"   Certifique-se de criar um secret chamado 'GITHUB_PAT' com seu Personal Access Token.\")\n",
        "\n",
        "    raise e # Parar execu√ß√£o se n√£o conseguir carregar o PAT\n",
        "\n",
        "# --- CONFIGURA√á√ÉO DO GITHUB ---\n",
        "# Monta a URL com o PAT para autentica√ß√£o\n",
        "REPO_OWNER = \"camila-f-romero\"\n",
        "REPO_NAME = \"MBACDIA-IAGen\"\n",
        "REPO_URL_COM_PAT = f\"https://{GITHUB_PAT}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "NOME_REPO_LOCAL = REPO_NAME\n",
        "NOME_PASTA_PDFS_NO_REPO = \"arquivos-projeto\"\n",
        "\n",
        "# --- Clonar/Atualizar Reposit√≥rio ---\n",
        "DIRETORIO_ATUAL = os.getcwd()\n",
        "print(f\"Diret√≥rio de trabalho atual: {DIRETORIO_ATUAL}\")\n",
        "CAMINHO_REPO_LOCAL_ABS = os.path.join(DIRETORIO_ATUAL, NOME_REPO_LOCAL)\n",
        "print(f\"Caminho absoluto esperado para o reposit√≥rio local: {CAMINHO_REPO_LOCAL_ABS}\")\n",
        "\n",
        "if not os.path.exists(CAMINHO_REPO_LOCAL_ABS):\n",
        "    print(f\"Clonando reposit√≥rio (usando PAT) para '{CAMINHO_REPO_LOCAL_ABS}'...\")\n",
        "    # Usa a URL com o PAT. N√£o precisa mais de GIT_TERMINAL_PROMPT=0 ou -c credential.helper=\n",
        "    ret_code = os.system(f\"git clone {REPO_URL_COM_PAT} '{CAMINHO_REPO_LOCAL_ABS}'\")\n",
        "    if ret_code == 0:\n",
        "        print(\"‚úÖ Reposit√≥rio clonado com sucesso.\")\n",
        "    else:\n",
        "        print(f\"‚ùå Falha ao clonar reposit√≥rio (C√≥digo de retorno: {ret_code}). Verifique o PAT e a URL.\")\n",
        "        # Limpa o PAT da mem√≥ria por seguran√ßa\n",
        "        GITHUB_PAT = None\n",
        "        raise RuntimeError(\"Falha no Git Clone com PAT\")\n",
        "else:\n",
        "    print(f\"Reposit√≥rio '{NOME_REPO_LOCAL}' j√° existe em '{CAMINHO_REPO_LOCAL_ABS}'.\")\n",
        "    print(\"Verificando atualiza√ß√µes no reposit√≥rio (usando PAT)...\")\n",
        "\n",
        "    ret_code = os.system(f\"cd '{CAMINHO_REPO_LOCAL_ABS}' && git pull\")\n",
        "    if ret_code == 0:\n",
        "         print(\"‚úÖ Reposit√≥rio atualizado com sucesso.\")\n",
        "    else:\n",
        "         print(f\"‚ö†Ô∏è Falha ao atualizar reposit√≥rio com 'git pull' (C√≥digo: {ret_code}).\")\n",
        "\n",
        "# Limpa o PAT da mem√≥ria ap√≥s o uso inicial por seguran√ßa\n",
        "GITHUB_PAT = None\n",
        "\n",
        "# --- Define o Caminho para a Pasta de PDFs ---\n",
        "CAMINHO_PASTA_PDFS = os.path.join(CAMINHO_REPO_LOCAL_ABS, NOME_PASTA_PDFS_NO_REPO)\n",
        "print(f\"Caminho completo esperado para a pasta de PDFs: {CAMINHO_PASTA_PDFS}\")\n",
        "\n",
        "# --- Verifica√ß√£o Final ---\n",
        "print(f\"\\nVerificando novamente a exist√™ncia de '{CAMINHO_REPO_LOCAL_ABS}'...\")\n",
        "if os.path.exists(CAMINHO_REPO_LOCAL_ABS):\n",
        "    print(f\"‚úÖ Diret√≥rio do reposit√≥rio '{NOME_REPO_LOCAL}' encontrado.\")\n",
        "    try:\n",
        "        print(f\"   Conte√∫do encontrado na raiz do reposit√≥rio clonado:\", os.listdir(CAMINHO_REPO_LOCAL_ABS))\n",
        "        print(f\"\\nVerificando a exist√™ncia da pasta de PDFs '{CAMINHO_PASTA_PDFS}'...\")\n",
        "        if os.path.exists(CAMINHO_PASTA_PDFS):\n",
        "            print(f\"‚úÖ Pasta de PDFs encontrada em: '{CAMINHO_PASTA_PDFS}'\")\n",
        "        else:\n",
        "            print(f\"‚ùå ATEN√á√ÉO: A pasta de PDFs '{NOME_PASTA_PDFS_NO_REPO}' N√ÉO foi encontrada dentro de '{CAMINHO_REPO_LOCAL_ABS}'.\")\n",
        "            print(f\"   Verifique se o nome '{NOME_PASTA_PDFS_NO_REPO}' est√° correto e se a pasta existe no reposit√≥rio GitHub.\")\n",
        "    except Exception as list_err:\n",
        "        print(f\"‚ùå Erro ao listar conte√∫do de '{CAMINHO_REPO_LOCAL_ABS}': {list_err}\")\n",
        "else:\n",
        "    print(f\"‚ùå Erro Cr√≠tico: O diret√≥rio do reposit√≥rio '{NOME_REPO_LOCAL}' n√£o foi encontrado ap√≥s a tentativa de clonagem/atualiza√ß√£o.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-57foDR_RmgR",
        "outputId": "e6ba4736-83d3-43dc-8cfc-87c20fe8acd0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Chave OpenAI carregada com sucesso: sk-pr...kRwA\n",
            "‚úÖ GitHub PAT carregado do userdata.\n",
            "Diret√≥rio de trabalho atual: /content\n",
            "Caminho absoluto esperado para o reposit√≥rio local: /content/MBACDIA-IAGen\n",
            "Reposit√≥rio 'MBACDIA-IAGen' j√° existe em '/content/MBACDIA-IAGen'.\n",
            "Verificando atualiza√ß√µes no reposit√≥rio (usando PAT)...\n",
            "‚úÖ Reposit√≥rio atualizado com sucesso.\n",
            "Caminho completo esperado para a pasta de PDFs: /content/MBACDIA-IAGen/arquivos-projeto\n",
            "\n",
            "Verificando novamente a exist√™ncia de '/content/MBACDIA-IAGen'...\n",
            "‚úÖ Diret√≥rio do reposit√≥rio 'MBACDIA-IAGen' encontrado.\n",
            "   Conte√∫do encontrado na raiz do reposit√≥rio clonado: ['.git', 'faiss_index_anpd_acts', 'arquivos-projeto']\n",
            "\n",
            "Verificando a exist√™ncia da pasta de PDFs '/content/MBACDIA-IAGen/arquivos-projeto'...\n",
            "‚úÖ Pasta de PDFs encontrada em: '/content/MBACDIA-IAGen/arquivos-projeto'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 4: Fun√ß√µes Auxiliares (Extra√ß√£o de Texto PDF/OCR) ===\n",
        "\n",
        "# Fun√ß√£o b√°sica de extra√ß√£o com PyPDF2\n",
        "def extrair_texto_pypdf2(pdf_path):\n",
        "    texto = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            leitor = PdfReader(f)\n",
        "            if leitor.is_encrypted:\n",
        "                try:\n",
        "                    leitor.decrypt(\"\") # Tenta descriptografar com senha vazia\n",
        "                except Exception as decrypt_err:\n",
        "                    print(f\"  -> Aviso: PDF criptografado e falha ao descriptografar '{os.path.basename(pdf_path)}': {decrypt_err}\")\n",
        "                    # return \"\" # Ou pode tentar extrair mesmo assim se a criptografia for leve\n",
        "\n",
        "            for pagina in leitor.pages:\n",
        "                try:\n",
        "                    texto_pagina = pagina.extract_text()\n",
        "                    if texto_pagina:\n",
        "                        texto += texto_pagina + \"\\n\" # Adicionar nova linha entre p√°ginas\n",
        "                except Exception as page_err:\n",
        "                     print(f\"  -> Erro ao extrair texto da p√°gina em '{os.path.basename(pdf_path)}': {page_err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Erro PyPDF2 em '{os.path.basename(pdf_path)}': {e}\")\n",
        "    return texto.strip()\n",
        "\n",
        "# Fun√ß√£o de extra√ß√£o com OCR (Tesseract via pdf2image)\n",
        "def extrair_texto_ocr(pdf_path):\n",
        "    texto_total = \"\"\n",
        "    print(f\"  -> Tentando OCR em: {os.path.basename(pdf_path)}\")\n",
        "    try:\n",
        "        imagens = convert_from_path(\n",
        "            pdf_path,\n",
        "            dpi=300, # Boa resolu√ß√£o para OCR\n",
        "            poppler_path=\"/usr/bin\",\n",
        "            thread_count=2 # Ajuste se necess√°rio\n",
        "        )\n",
        "        if not imagens:\n",
        "             print(f\"  -> Aviso: pdf2image n√£o retornou imagens para OCR em '{os.path.basename(pdf_path)}'.\")\n",
        "             return \"\"\n",
        "\n",
        "        for i, img in enumerate(imagens):\n",
        "            try:\n",
        "                texto_pagina = pytesseract.image_to_string(img, lang='por', config='--psm 6') # Tenta detectar layout\n",
        "                texto_total += f\"\\n--- P√°gina OCR {i+1} ---\\n{texto_pagina}\"\n",
        "            except Exception as ocr_err:\n",
        "                 print(f\"    -> Erro OCR na p√°gina {i+1}: {ocr_err}\")\n",
        "        print(f\"  -> OCR conclu√≠do para: {os.path.basename(pdf_path)}\")\n",
        "        return texto_total.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Falha GERAL no OCR para '{os.path.basename(pdf_path)}': {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Fun√ß√£o inteligente que tenta PyPDF2 e usa OCR como fallback\n",
        "def extrair_texto_inteligente(pdf_path, limiar_ocr=150):\n",
        "    \"\"\"\n",
        "    Tenta extrair texto com PyPDF2. Se o texto for muito curto (abaixo do limiar),\n",
        "    tenta usar OCR. Retorna o texto mais longo obtido.\n",
        "    \"\"\"\n",
        "    print(f\"Processando: {os.path.basename(pdf_path)}\")\n",
        "    texto_normal = \"\"\n",
        "    texto_ocr = \"\"\n",
        "\n",
        "    texto_normal = extrair_texto_pypdf2(pdf_path)\n",
        "\n",
        "    if len(texto_normal) < limiar_ocr:\n",
        "        print(f\"  -> Texto PyPDF2 curto ({len(texto_normal)} chars). Ativando OCR...\")\n",
        "        texto_ocr = extrair_texto_ocr(pdf_path)\n",
        "\n",
        "        if len(texto_ocr) > len(texto_normal):\n",
        "             print(f\"  -> Usando resultado do OCR ({len(texto_ocr)} chars).\")\n",
        "             return texto_ocr\n",
        "        else:\n",
        "             print(f\"  -> Resultado do OCR n√£o foi melhor ({len(texto_ocr)} chars). Mantendo resultado PyPDF2.\")\n",
        "             return texto_normal\n",
        "    else:\n",
        "        # print(f\"  -> Extra√≠do via PyPDF2 ({len(texto_normal)} chars).\")\n",
        "        return texto_normal\n",
        "\n",
        "print(\"Fun√ß√µes auxiliares de extra√ß√£o definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ1mVQi6XkXh",
        "outputId": "48bc09e2-047f-47bf-de55-bfb9ff26dfb4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fun√ß√µes auxiliares de extra√ß√£o definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 5: Carregamento dos Documentos ===\n",
        "\n",
        "documentos_carregados = [] # Lista para guardar os Documentos LangChain\n",
        "\n",
        "print(\"\\n--- Iniciando Carregamento de Documentos ---\")\n",
        "# Verifica se o CAMINHO_PASTA_PDFS realmente existe e n√£o est√° vazio antes de prosseguir\n",
        "if not os.path.exists(CAMINHO_PASTA_PDFS) or not os.listdir(CAMINHO_PASTA_PDFS):\n",
        "     print(f\"üö® Erro Cr√≠tico: Pasta de PDFs '{CAMINHO_PASTA_PDFS}' n√£o encontrada ou vazia. Verifique a C√©lula 3 e o reposit√≥rio.\")\n",
        "     # Define a lista como vazia para as pr√≥ximas c√©lulas saberem que falhou\n",
        "     documentos_carregados = []\n",
        "else:\n",
        "    # Lista os arquivos PDF encontrados para processamento\n",
        "    arquivos_pdf_encontrados = [f for f in os.listdir(CAMINHO_PASTA_PDFS) if f.lower().endswith('.pdf')]\n",
        "    print(f\"Encontrados {len(arquivos_pdf_encontrados)} arquivo(s) PDF em '{CAMINHO_PASTA_PDFS}'.\")\n",
        "\n",
        "    # Tenta carregar usando a extra√ß√£o inteligente para cada arquivo\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf_encontrados:\n",
        "        caminho_completo = os.path.join(CAMINHO_PASTA_PDFS, nome_arquivo)\n",
        "        texto_extraido = extrair_texto_inteligente(caminho_completo, limiar_ocr=150)\n",
        "        if texto_extraido:\n",
        "            doc = Document(page_content=texto_extraido, metadata={'source': caminho_completo})\n",
        "            documentos_carregados.append(doc)\n",
        "            print(f\"  -> OK: {nome_arquivo} ({len(texto_extraido)} chars)\") # Confirma√ß√£o\n",
        "        else:\n",
        "             print(f\"  -> Falha/Vazio: {nome_arquivo}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n‚úÖ Carregamento conclu√≠do: {len(documentos_carregados)} documentos processados e carregados.\")\n",
        "\n",
        "# Verifica√ß√£o final\n",
        "if documentos_carregados:\n",
        "    print(f\"\\n--- Processamento Finalizado ---\")\n",
        "    print(f\"Total de Documentos LangChain prontos para divis√£o: {len(documentos_carregados)}\")\n",
        "else:\n",
        "    print(\"\\nüö® ATEN√á√ÉO: Nenhum documento foi carregado com sucesso. Verifique os logs acima.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFMGnDviYkjI",
        "outputId": "f79f343b-41a9-4578-9377-cc188aaf7ff9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Carregamento de Documentos ---\n",
            "Encontrados 9 arquivo(s) PDF em '/content/MBACDIA-IAGen/arquivos-projeto'.\n",
            "Processando: compress ocr mou-anpd-aepd-pt_compressed.pdf\n",
            "  -> OK: compress ocr mou-anpd-aepd-pt_compressed.pdf (14473 chars)\n",
            "Processando: compress ocr cade act-tarjado-compactado_compressed.pdf\n",
            "  -> OK: compress ocr cade act-tarjado-compactado_compressed.pdf (35445 chars)\n",
            "Processando: compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf\n",
            "  -> OK: compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf (32508 chars)\n",
            "Processando: compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf\n",
            "  -> OK: compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf (27441 chars)\n",
            "Processando: compress ocr CGU Acordo_de_cooperacao_ANPD (1)_compressed.pdf\n",
            "  -> OK: compress ocr CGU Acordo_de_cooperacao_ANPD (1)_compressed.pdf (36755 chars)\n",
            "Processando: compress ocr EXTRATO_CARTA_DE_ACEITE_DOU_compressed.pdf\n",
            "  -> OK: compress ocr EXTRATO_CARTA_DE_ACEITE_DOU_compressed.pdf (1038 chars)\n",
            "Processando: compress ocr act-senacon_ocultado (1)_compressed.pdf\n",
            "  -> OK: compress ocr act-senacon_ocultado (1)_compressed.pdf (17794 chars)\n",
            "Processando: compress ocr ans ANPD_ACT_assinado_2024 (1)_compressed.pdf\n",
            "  -> OK: compress ocr ans ANPD_ACT_assinado_2024 (1)_compressed.pdf (21826 chars)\n",
            "Processando: compress ocr act-nicbr-publico_compressed.pdf\n",
            "  -> OK: compress ocr act-nicbr-publico_compressed.pdf (29145 chars)\n",
            "\n",
            "‚úÖ Carregamento conclu√≠do: 9 documentos processados e carregados.\n",
            "\n",
            "--- Processamento Finalizado ---\n",
            "Total de Documentos LangChain prontos para divis√£o: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 6: Divis√£o dos Documentos em Chunks ===\n",
        "\n",
        "chunks = [] # Inicializa a lista de chunks\n",
        "\n",
        "if documentos_carregados:\n",
        "    print(\"\\n--- Iniciando Divis√£o em Chunks ---\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,        # Tamanho do chunk\n",
        "        chunk_overlap=150,      # Sobreposi√ß√£o\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # Separadores comuns\n",
        "        keep_separator=False,\n",
        "        add_start_index=True,   # Adiciona metadado com √≠ndice inicial\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_documents(documentos_carregados)\n",
        "    print(f\"‚úÖ Documentos divididos em {len(chunks)} chunks.\")\n",
        "\n",
        "\n",
        "    tamanhos = [len(c.page_content) for c in chunks]\n",
        "    print(f\"   Tamanhos (Min/M√©dio/Max): {min(tamanhos)} / {int(np.mean(tamanhos))} / {max(tamanhos)}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è N√£o h√° documentos carregados para dividir. Pule esta c√©lula ou corrija a C√©lula 5.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eLbuYd9Yskf",
        "outputId": "a5988983-99ac-4326-dec3-310aa7c64559"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Divis√£o em Chunks ---\n",
            "‚úÖ Documentos divididos em 256 chunks.\n",
            "   Tamanhos (Min/M√©dio/Max): 135 / 945 / 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 7: Cria√ß√£o do Banco de Vetores (FAISS) ===\n",
        "\n",
        "banco_vetores = None # Inicializa a vari√°vel\n",
        "\n",
        "if chunks: # S√≥ prossiga se houver chunks\n",
        "    print(\"\\n--- Iniciando Cria√ß√£o do Banco de Vetores FAISS ---\")\n",
        "    try:\n",
        "        embeddings = OpenAIEmbeddings() # Modelo padr√£o: text-embedding-ada-002\n",
        "\n",
        "        print(f\"Gerando embeddings e criando √≠ndice FAISS para {len(chunks)} chunks...\")\n",
        "        banco_vetores = FAISS.from_documents( # Usa os chunks\n",
        "            documents=chunks,\n",
        "            embedding=embeddings\n",
        "        )\n",
        "        print(f\"‚úÖ Banco de vetores FAISS criado com sucesso com {banco_vetores.index.ntotal} vetores.\")\n",
        "\n",
        "        # Opcional: Salvar o √≠ndice localmente\n",
        "        # try:\n",
        "        #    indice_path = \"meu_indice_faiss_colab\"\n",
        "        #    banco_vetores.save_local(indice_path)\n",
        "        #    print(f\"‚úÖ √çndice FAISS salvo localmente em '{indice_path}'.\")\n",
        "        # except Exception as save_err:\n",
        "        #    print(f\"‚ö†Ô∏è Erro ao salvar √≠ndice FAISS: {save_err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao criar o banco de vetores FAISS: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è N√£o h√° chunks para criar o banco de vetores. Pule esta c√©lula ou corrija a C√©lula 6.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBus-zvrYv3Z",
        "outputId": "261b4f89-8b37-49a6-d26e-2911d116004a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Cria√ß√£o do Banco de Vetores FAISS ---\n",
            "Gerando embeddings e criando √≠ndice FAISS para 256 chunks...\n",
            "‚úÖ Banco de vetores FAISS criado com sucesso com 256 vetores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 7.5: Salvar √çndice FAISS ===\n",
        "if banco_vetores:\n",
        "    NOME_PASTA_INDICE = \"faiss_index_anpd_acts\"\n",
        "    try:\n",
        "        banco_vetores.save_local(NOME_PASTA_INDICE)\n",
        "        print(f\"‚úÖ √çndice FAISS salvo com sucesso na pasta '{NOME_PASTA_INDICE}'.\")\n",
        "        print(\"   Arquivos criados:\", os.listdir(NOME_PASTA_INDICE))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao salvar √≠ndice FAISS localmente: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Banco de vetores n√£o existe, n√£o √© poss√≠vel salvar o √≠ndice.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26QSl5rJZwTE",
        "outputId": "d4460d7f-9c6c-4cb7-cb32-1f5c899c5826"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ √çndice FAISS salvo com sucesso na pasta 'faiss_index_anpd_acts'.\n",
            "   Arquivos criados: ['index.faiss', 'index.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C√âLULA 8: Configura√ß√£o e Teste da Chain RetrievalQA ===\n",
        "\n",
        "qa_chain_instance = None # Inicializa a vari√°vel\n",
        "\n",
        "if banco_vetores: # S√≥ prossiga se o banco de vetores existir\n",
        "    print(\"\\n--- Configurando a Chain RetrievalQA ---\")\n",
        "    try:\n",
        "        # Configurar o Retriever\n",
        "        retriever = banco_vetores.as_retriever(\n",
        "            search_type=\"similarity\", # Busca por similaridade\n",
        "            search_kwargs={'k': 6}    # Retorna os 6 chunks mais relevantes\n",
        "        )\n",
        "        print(f\"Retriever configurado (k={retriever.search_kwargs.get('k', 'Padr√£o')}).\")\n",
        "\n",
        "        # Configurar o LLM\n",
        "        llm = ChatOpenAI(\n",
        "            model_name='gpt-3.5-turbo',\n",
        "            temperature=0.3\n",
        "        )\n",
        "        print(f\"LLM configurado: {llm.model_name} (Temperature={llm.temperature})\")\n",
        "\n",
        "        # Criar a Chain RetrievalQA\n",
        "        qa_chain_instance = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\", # Combina contexto e pergunta num √∫nico prompt\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True, # Retorna os chunks usados\n",
        "            chain_type_kwargs={\"prompt\": None} # Usar prompt padr√£o do Langchain para \"stuff\"\n",
        "        )\n",
        "        print(\"‚úÖ Chain RetrievalQA criada com sucesso!\")\n",
        "\n",
        "        # --- Teste ---\n",
        "        print(\"\\n--- Testando a Chain ---\")\n",
        "        # Use uma pergunta relevante para os seus documentos ACTs\n",
        "        pergunta_teste = \"Qual o objeto do acordo de coopera√ß√£o t√©cnica entre ANPD e TSE?\"\n",
        "        # pergunta_teste = \"Quais as obriga√ß√µes da ANPD no acordo com o CADE?\"\n",
        "        # pergunta_teste = \"Qual a vig√™ncia do acordo entre CGU e ANPD?\"\n",
        "\n",
        "        print(f\"\\nPergunta: {pergunta_teste}\")\n",
        "\n",
        "        try:\n",
        "             # Use .invoke para Langchain >= 0.1.0\n",
        "             resposta = qa_chain_instance.invoke({\"query\": pergunta_teste})\n",
        "             # Para vers√µes mais antigas, pode ser necess√°rio usar:\n",
        "             # resposta = qa_chain_instance({\"query\": pergunta_teste})\n",
        "\n",
        "             print(\"\\n--- Resposta Gerada ---\")\n",
        "             print(resposta.get('result', 'Nenhuma resposta encontrada.'))\n",
        "\n",
        "             print(\"\\n--- Documentos Fonte Utilizados ---\")\n",
        "             if resposta.get('source_documents'):\n",
        "                 fontes_usadas = set() # Para evitar listar a mesma fonte m√∫ltiplas vezes\n",
        "                 for i, doc in enumerate(resposta['source_documents']):\n",
        "                     source_file = os.path.basename(doc.metadata.get('source', 'N/A'))\n",
        "                     if source_file not in fontes_usadas:\n",
        "                          print(f\"- {source_file}\")\n",
        "                          fontes_usadas.add(source_file)\n",
        "                     # Opcional: mostrar trecho do chunk\n",
        "                     # print(f\"  Chunk (In√≠cio: {doc.metadata.get('start_index', '?')}): {doc.page_content[:150]}...\")\n",
        "                 if not fontes_usadas:\n",
        "                      print(\"Nenhum nome de arquivo encontrado nos metadados dos documentos fonte.\")\n",
        "             else:\n",
        "                 print(\"Nenhum documento fonte retornado pela chain.\")\n",
        "\n",
        "        except Exception as query_err:\n",
        "             print(f\"\\n‚ùå Erro ao executar a pergunta na chain: {query_err}\")\n",
        "             traceback.print_exc()\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao configurar a chain QA: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Banco de vetores n√£o foi criado. N√£o √© poss√≠vel configurar ou testar a Chain QA.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- CONTE√öDO dos Documentos Fonte Recuperados ---\")\n",
        "if resposta.get('source_documents'):\n",
        "    for i, doc in enumerate(resposta['source_documents']):\n",
        "        print(f\"--- Fonte {i+1} ({os.path.basename(doc.metadata.get('source', 'N/A'))}) ---\")\n",
        "        print(doc.page_content) # Imprime o conte√∫do completo do chunk\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"Nenhum documento fonte recuperado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivPFPu75Y1H5",
        "outputId": "d62834b3-d77f-4533-9814-6bcbd26eec5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configurando a Chain RetrievalQA ---\n",
            "Retriever configurado (k=6).\n",
            "LLM configurado: gpt-3.5-turbo (Temperature=0.3)\n",
            "‚úÖ Chain RetrievalQA criada com sucesso!\n",
            "\n",
            "--- Testando a Chain ---\n",
            "\n",
            "Pergunta: Qual o objeto do acordo de coopera√ß√£o t√©cnica entre ANPD e TSE?\n",
            "\n",
            "--- Resposta Gerada ---\n",
            "O objeto do acordo de coopera√ß√£o t√©cnica entre a Autoridade Nacional de Prote√ß√£o de Dados (ANPD) e o Tribunal Superior Eleitoral (TSE) √© a realiza√ß√£o de a√ß√µes conjuntas para orienta√ß√£o e monitoramento da implementa√ß√£o da Lei Geral de Prote√ß√£o de Dados (LGPD) no contexto eleitoral.\n",
            "\n",
            "--- Documentos Fonte Utilizados ---\n",
            "- compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf\n",
            "- compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf\n",
            "- compress ocr act-senacon_ocultado (1)_compressed.pdf\n",
            "- compress ocr cade act-tarjado-compactado_compressed.pdf\n",
            "\n",
            "--- CONTE√öDO dos Documentos Fonte Recuperados ---\n",
            "--- Fonte 1 (compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf) ---\n",
            "concessdo de medidas preventivas de compet√©ncia do TSE; \n",
            "- Subsidiar a ANPD quanto ao conte√∫do de qualquer material a ser desenvolvido em conjunto, inclusive a \n",
            "partir da orienta√ß√£o t√©cnica quanto ao conte√∫do e √† interpreta√ß√£o da legisla√ß√£o eleitoral, suas diretrizes \n",
            "interpretativas e, ainda, por meio da indica√ß√£o de fontes de pesquisa bibliogr√°fica;\n",
            "m\"- Realizar, em conjunto com a ANPD, estudos, pesquisas e a√ß√µes de capacita√ß√£o relacionados ao objeto do \n",
            "presente ACT; \n",
            "V- Aprovar, em conjunto com a ANPD, os principios e crit√©rios a serem utilizados para a elaboragdo de material \n",
            "orientativo em cumprimento ao objeto do presente Acordo; \n",
            "V- Elaborar, em conjunto com a ANPD, material orientativo referente a aplicagdo das disposi¬¢des da LGPD no \n",
            "contexto eleitoral; e \n",
            "VI- Informar a ANPD a respeito de reunides, encontros, workshops, visitas t√©cnicas, cursos, palestras, \n",
            "confer√©ncias, semindrios, simp√≥sios, congressos ou quaisquer eventos que possam contribuir na capacitagao,\n",
            "--------------------\n",
            "--- Fonte 2 (compress ocr TSE-acordo-cooperacao-tecnica-anpd-lgpd_compressed.pdf) ---\n",
            "sentido de orientar acerca da importancia do tratamento de dados pessoais em conformidade com a LGPD durante campanhas \n",
            "politico-eleitorais; \n",
            "CONSIDERANDO a compatibilidade das finalidades institucionais dos Participes com o objeto deste Acordo de Cooperagdo T√©cnica e, \n",
            "ainda, o interesse comum na realizagdo das a√ß√µes que especifica; \n",
            "CONSIDERANDO que a atuagdo articulada entre a ANPD e o TSE proporcionara maior seguranga juridica e efetividade nas a√ß√µes \n",
            "relacionadas a aplica√ß√£o da LGPD e a garantia dos direitos √† privacidade e a prote√ß√£o de dados no contexto eleitoral; \n",
            "CONSIDERANDO o disposto nos arts. 55-J, $ 42, e 55-K, paragrafo √∫nico, da Lei 13.709, de 14 de agosto de 2018; \n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERAGAO TECNICA, tendo em vista o que consta do Processo n¬∫ 00261.001067/2021-23 e em \n",
            "observancia, no que couber, as disposi¬¢cdes da Lei n¬∫ 8.666, de 21 de julho de 1993, mediante as clausulas e condigdes a seguir: \n",
            "1 CLAUSULA PRIMEIRA ‚Äî DO OBJETO\n",
            "--------------------\n",
            "--- Fonte 3 (compress ocr CGE MG SUPER_PR - 4556235 - Contrato (1)_compressed.pdf) ---\n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERAGAO TECNICA, tendo em vista o que consta do Processo SUPER.GOV (ANPD) n¬∫ 00261.000130/2022-95 e em \n",
            "observancia, no que couber, as disposiges da Lei n28.666, de 21 de julho de 1993, mediante as cl√©usulas e condi√ß√µes a seguir: \n",
            "CLAUSULA PRIMEIRA - DO OBJETO \n",
            "O presente ACORDO DE COOPERA√á√ÉO TECNICA ‚Äî ACT tem por objeto a realiza√ß√£o de a√ß√µes conjuntas de interesse m√∫tuo, que possibilitar√£o a orienta√ß√£o e o \n",
            "monitoramento quanto √† implementa√ß√£o da LGPD, pela administra√ß√£o p√∫blica estadual. \n",
            "Subcl√°usula √∫nica. O objetivo deste ACT estd alinhado com as diretrizes descritas na Lei n¬∫ 13.709, de 14 de agosto de 2018 ‚Äî Lei Geral de Prote√ß√£o de Dados \n",
            "Pessoais, assim como com o Decreto n¬∫ 47.774 de 03 de dezembro de 2019, que disp√µe sobre a estrutura organica da Controladoria-Geral do Estado. \n",
            "CLAUSULA SEGUNDA - DO PLANO DE TRABALHO\n",
            "--------------------\n",
            "--- Fonte 4 (compress ocr act-senacon_ocultado (1)_compressed.pdf) ---\n",
            "mediante as seguintes clausulas e condigdes: \n",
            "CL√ÅUSULA PRIMEIRA - DO OBJETO \n",
            "O presente Acordo tem por objeto a coopera√ß√£o t√©cnica entre a ANPD e a SENACON, a ser \n",
            "executada na cidade de Bras√≠lia (DF), com vistas a promover a√ß√µes conjuntas sobre assuntos \n",
            "de interesse rec√≠proco, dentre as quais se incluem: \n",
            "a) Apoio institucional e interc√¢mbio de informa√ß√µes relativas √†s suas respectivas esferas de \n",
            "atua√ß√£o; \n",
            "b) Compartilhamento de informa√ß√µes agregadas e de dados estat√≠sticos quanto a \n",
            "reclama√ß√µes de consumidores relacionadas √† prote√ß√£o de dados pessoais, em especial \n",
            "aquelas registradas no Sistema Nacional de Informa√ß√µes de Defesa do Consumidor ‚Äî \n",
            "SINDEC e nas bases de dados do Consumidor.gov.br; \n",
            "c) Uniformiza√ß√£o de entendimentos e coordena√ß√£o de a√ß√µes, inclusive no que tange ao \n",
            "endere√ßamento de reclama√ß√µes de consumidores e √† atua√ß√£o no caso de incidentes de \n",
            "seguran√ßa envolvendo dados pessoais de consumidores;\n",
            "--------------------\n",
            "--- Fonte 5 (compress ocr cade act-tarjado-compactado_compressed.pdf) ---\n",
            "efetividadepara o alcance da prote√ß√£o de dados quando da sua utilizagio abusiva por parte de agentes \n",
            "econdmicos; e \n",
            "CONSIDERANDO o disposto no inciso XI, do art. 10 da Lei n¬∞ 12.529, de 30 de novembro de 2011, e \n",
            "o previstos no art. 55-J da Lei n. 13.079, de 14 de agosto de 2018; \n",
            "RESOLVEM \n",
            "Celebrar o presente ACORDO DE COOPERACAO TECNICA, tendo em vista o que consta do \n",
            "Processo n¬∫ 08700.002088/2021-51 e em observancia as disposigdes da Lei n¬∫ 8666/1993, legislagio \n",
            "correlacionada √†s politicas publicas e suas alteragdes, mediante as cldusulas e condigdes a seguir: \n",
            "CLAUSULA PRIMEIRA - DO OBJETO E DO OBJETIVO \n",
            "O objeto do presente ACORDO DE COOPERACAO TECNICA tem como finalidade a institui√ß√£o de \n",
            "coopera√ß√£o t√©cnica entre o CADE e a ANPD, para viabilizar a√ß√µes a serem adotadas pelas partes, de \n",
            "forma conjunta e coordenada, quando da ocorr√©ncia de situagdes que interseccionam ambas as esferas de \n",
            "compet√©ncias.\n",
            "--------------------\n",
            "--- Fonte 6 (compress ocr act-senacon_ocultado (1)_compressed.pdf) ---\n",
            "CPF: ‚Äî Cargo: Secret√°ria Nacional do Consumidor \n",
            "2. Identifica√ß√£o do Objeto \n",
            "T√≠tulo do Projeto: Acordo de Coopera√ß√£o T√©cnica entre a \n",
            "Autoridade Nacional de Prote√ß√£o de Dados ‚Äî ANPD, da \n",
            "Presid√™ncia da Rep√∫blica, e a Secretaria Nacional do Per√≠odo de Execu√ß√£o \n",
            "Consumidor do Minist√©rio da Justi√ßa e Seguran√ßa P√∫blica ‚Äî \n",
            "Mmisp \n",
            "Inicio T√©rmino \n",
            "o X Processo n¬∫ 08012.000596/2021-53 Pata de 24 meses ap√©s \n",
            "assinatura do \" a assinatura acordo \n",
            "Objeto do Projeto: promo√ß√£o de a√ß√µes conjuntas nas √°reas de prote√ß√£o de dados pessoais e defesa \n",
            "do consumidor, incluindo interc√¢mbio de informa√ß√µes, uniformiza√ß√£o de entendimentos, \n",
            "coopera√ß√£o quanto a a√ß√µes de fiscaliza√ß√£o, desenvolvimento de a√ß√µes de educa√ß√£o, forma√ß√£o e \n",
            "capacita√ß√£o e elabora√ß√£o de estudos e pesquisas. \n",
            "3. Diagn√≥stico, abrang√™ncia e justificativa \n",
            "A ANPD foi institu√≠da pela Lei n¬∫ 13.709/2018 (LGPD), com compet√™ncia para zelar pela \n",
            "prote√ß√£o de dados pessoais e para fiscalizar e aplicar san√ß√µes em caso de tratamento de\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# === C√âLULA 9: Criar Arquivo da Aplica√ß√£o (app.py) ===\n",
        "# ========================================================\n",
        "\n",
        "FAISS_INDEX_PATH_APP = \"faiss_index_anpd_acts\"\n",
        "\n",
        "OPENAI_SECRET_NAME_APP = \"OPENAI_API_KEY\"\n",
        "\n",
        "# Ajuste os par√¢metros do LLM e Retriever para o App Streamlit.\n",
        "K_RETRIEVER_APP = 4\n",
        "LLM_MODEL_APP = 'gpt-4o-mini'\n",
        "LLM_TEMP_APP = 0.3\n",
        "\n",
        "# Personalize os textos da interface do usu√°rio.\n",
        "APP_TITLE = \"üñäüìë Chatbot Consulta ACTs ANPD\"\n",
        "APP_HEADER = \"Consulte informa√ß√µes sobre Acordos de Coopera√ß√£o T√©cnica da ANPD\"\n",
        "APP_INPUT_LABEL = \"Digite sua pergunta sobre os ACTs:\"\n",
        "APP_BUTTON_TEXT = \"Buscar Resposta\"\n",
        "\n",
        "\n",
        "# Cria o arquivo app.py com o c√≥digo do Streamlit\n",
        "print(f\"\\n--- Criando arquivo app.py ---\")\n",
        "# Usamos uma string multi-linha normal e formatamos as vari√°veis do NOTEBOOK nela.\n",
        "# As f-strings que devem ser interpretadas pelo app.py em runtime precisam ter\n",
        "# suas chaves escapadas com chaves duplas {{ variavel }}.\n",
        "writefile_content = f\"\"\"\n",
        "import streamlit as st\n",
        "import os\n",
        "import time # Para simular processamento\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "import traceback # Para mostrar erros no app\n",
        "\n",
        "# --- Configura√ß√µes e Carregamento de Recursos (com cache) ---\n",
        "\n",
        "# Carregar Chave API (Prioriza st.secrets)\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    # Tenta carregar do secrets.toml (para deploy no Streamlit Cloud)\n",
        "    OPENAI_API_KEY = st.secrets[\"{OPENAI_SECRET_NAME_APP}\"]\n",
        "    print(\"OpenAI Key carregada do st.secrets\") # Log interno\n",
        "except (FileNotFoundError, KeyError):\n",
        "    print(\"Secret '{OPENAI_SECRET_NAME_APP}' n√£o encontrado no st.secrets. Tentando vari√°vel de ambiente...\")\n",
        "    # Tenta carregar de vari√°veis de ambiente\n",
        "    OPENAI_API_KEY = os.environ.get('{OPENAI_SECRET_NAME_APP}')\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\"OpenAI Key carregada da vari√°vel de ambiente.\")\n",
        "    else:\n",
        "        st.error(\"Chave API da OpenAI ('{OPENAI_SECRET_NAME_APP}') n√£o configurada! Configure em st.secrets ou vari√°vel de ambiente.\")\n",
        "        st.stop() # Para a execu√ß√£o se n√£o tiver a chave\n",
        "\n",
        "# Define a vari√°vel de ambiente para Langchain usar\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Caminho para o √≠ndice FAISS salvo\n",
        "FAISS_INDEX_PATH = \"{FAISS_INDEX_PATH_APP}\"\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Carregando base de conhecimento (√≠ndice FAISS)...\")\n",
        "def load_faiss_index(index_path):\n",
        "    if not os.path.exists(index_path):\n",
        "         # CORRE√á√ÉO: Escapar chaves ao redor de index_path\n",
        "         st.error(f\"Pasta do √≠ndice FAISS n√£o encontrada em '{{index_path}}'. Verifique se a pasta existe no reposit√≥rio junto com app.py.\")\n",
        "         st.stop()\n",
        "    try:\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        vector_store = FAISS.load_local(\n",
        "            index_path,\n",
        "            embeddings,\n",
        "            allow_dangerous_deserialization=True\n",
        "        )\n",
        "        return vector_store\n",
        "    except Exception as e:\n",
        "        # CORRE√á√ÉO: Escapar chaves ao redor de e\n",
        "        st.error(f\"Erro ao carregar √≠ndice FAISS: {{e}}\")\n",
        "        st.error(traceback.format_exc())\n",
        "        st.stop()\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Preparando o assistente (chain QA)...\")\n",
        "def create_qa_chain(_vector_store):\n",
        "    try:\n",
        "        # Usa vari√°veis definidas no in√≠cio do script app.py (n√£o precisa escapar)\n",
        "        llm = ChatOpenAI(model_name='{LLM_MODEL_APP}', temperature={LLM_TEMP_APP})\n",
        "        retriever = _vector_store.as_retriever(search_kwargs={{'k': {K_RETRIEVER_APP}}})\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True\n",
        "        )\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "         # CORRE√á√ÉO: Escapar chaves ao redor de e\n",
        "         st.error(f\"Erro ao criar a chain QA: {{e}}\")\n",
        "         st.error(traceback.format_exc())\n",
        "         st.stop()\n",
        "\n",
        "# --- Carregar Recursos ---\n",
        "vector_store_app = load_faiss_index(FAISS_INDEX_PATH)\n",
        "qa_chain_app = create_qa_chain(vector_store_app)\n",
        "st.success(\"Assistente pronto!\") # Mensagem de sucesso ap√≥s carregar tudo\n",
        "\n",
        "# --- Interface do Usu√°rio Streamlit ---\n",
        "st.title(\"{APP_TITLE}\")\n",
        "st.markdown(\"{APP_HEADER}\")\n",
        "st.divider()\n",
        "\n",
        "with st.form(\"input_form\"):\n",
        "    user_question = st.text_area(\"{APP_INPUT_LABEL}\", key=\"user_input\", height=100)\n",
        "    submitted = st.form_submit_button(\"{APP_BUTTON_TEXT}\")\n",
        "\n",
        "    if submitted:\n",
        "        if user_question:\n",
        "            with st.spinner(\"Buscando informa√ß√µes nos documentos...\"):\n",
        "                try:\n",
        "                    start_time = time.time()\n",
        "                    resposta = qa_chain_app.invoke({{\"query\": user_question}})\n",
        "                    end_time = time.time()\n",
        "\n",
        "                    st.markdown(\"### Resposta:\")\n",
        "                    st.info(resposta.get('result', \"N√£o foi poss√≠vel obter uma resposta.\"))\n",
        "                    st.caption(f\"Tempo de resposta: {{end_time - start_time:.2f}} segundos\") # Escapar aqui tamb√©m\n",
        "\n",
        "                    with st.expander(\"Ver Documentos Fonte Utilizados\"):\n",
        "                        if resposta.get('source_documents'):\n",
        "                            fontes_usadas = set()\n",
        "                            for doc in resposta['source_documents']:\n",
        "                                source_file = os.path.basename(doc.metadata.get('source', 'N/A'))\n",
        "                                if source_file not in fontes_usadas:\n",
        "                                    # Usar st.markdown para formatar como c√≥digo\n",
        "                                    st.markdown(f\"- `{source_file}`\")\n",
        "                                    fontes_usadas.add(source_file)\n",
        "                            if not fontes_usadas:\n",
        "                                 st.write(\"Nenhuma fonte espec√≠fica identificada nos metadados.\")\n",
        "                        else:\n",
        "                            st.write(\"Nenhum documento fonte foi retornado pela chain.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    # CORRE√á√ÉO: Escapar chaves ao redor de e\n",
        "                    st.error(f\"Ocorreu um erro ao processar sua pergunta:\")\n",
        "                    st.exception(e) # Mostra o erro detalhado no app\n",
        "        else:\n",
        "            st.warning(\"Por favor, digite uma pergunta.\")\n",
        "\n",
        "st.divider()\n",
        "st.caption(\"MBA IA & Big Data - Projeto GenAI RAG - Camila Falchetto\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Salva o conte√∫do no arquivo app.py\n",
        "try:\n",
        "  with open(\"app.py\", \"w\") as f:\n",
        "    f.write(writefile_content)\n",
        "  print(\"‚úÖ Arquivo app.py criado/sobrescrito com sucesso.\")\n",
        "except Exception as e:\n",
        "  print(f\"‚ùå Erro ao escrever o arquivo app.py: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "louSiVFOcOpg",
        "outputId": "d93bc959-dc0e-461f-a686-3114ebd50db2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Criando arquivo app.py ---\n",
            "‚úÖ Arquivo app.py criado/sobrescrito com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# === C√âLULA 10: Iniciar Streamlit em Background e Expor com Ngrok ===\n",
        "# ===================================================================\n",
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"--- Iniciando Streamlit em Background ---\")\n",
        "\n",
        "# Comando para rodar streamlit em background e salvar logs\n",
        "# nohup: evita que o processo morra se a conex√£o 'cair'\n",
        "# > streamlit_log.txt: redireciona a sa√≠da padr√£o para o arquivo\n",
        "# 2>&1: redireciona a sa√≠da de erro para o mesmo arquivo da sa√≠da padr√£o\n",
        "# &: executa em background\n",
        "streamlit_command = \"nohup streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > streamlit_log.txt 2>&1 &\"\n",
        "\n",
        "# Executa o comando para iniciar o Streamlit\n",
        "print(f\"Executando: {streamlit_command}\")\n",
        "os.system(streamlit_command)\n",
        "print(\"Comando para iniciar Streamlit enviado para background.\")\n",
        "print(\"Aguardando alguns segundos para o servidor Streamlit iniciar...\")\n",
        "time.sleep(10) # Pausa por 10 segundos (ajuste se necess√°rio)\n",
        "\n",
        "# Verifica se o Streamlit parece estar rodando (opcional, checando log)\n",
        "print(\"\\nVerificando log do Streamlit (streamlit_log.txt)...\")\n",
        "!tail streamlit_log.txt # Mostra as √∫ltimas linhas do log\n",
        "\n",
        "print(\"\\n--- Configurando Ngrok ---\")\n",
        "\n",
        "NGROK_SECRET_NAME = 'NGROK_AUTHTOKEN'\n",
        "\n",
        "try:\n",
        "    ngrok_auth = userdata.get(NGROK_SECRET_NAME)\n",
        "    if not ngrok_auth:\n",
        "         raise ValueError(f\"Secret '{NGROK_SECRET_NAME}' n√£o encontrado ou vazio.\")\n",
        "\n",
        "    # Mata processos ngrok anteriores se existirem\n",
        "    print(\"Tentando limpar processos ngrok antigos...\")\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Configura e conecta o ngrok\n",
        "    ngrok.set_auth_token(ngrok_auth)\n",
        "    print(\"Token Ngrok configurado.\")\n",
        "    # Expor a porta 8501\n",
        "    public_url = ngrok.connect(8501, proto='http')\n",
        "    print(\"\\n=======================================================================\")\n",
        "    print(f\"‚úÖ Aplica√ß√£o Streamlit deve estar rodando em background.\")\n",
        "    print(f\"   Acesso p√∫blico tempor√°rio via: {public_url}\")\n",
        "    print(\"   (Este t√∫nel permanecer√° ativo enquanto esta c√©lula Colab estiver ativa)\")\n",
        "    print(\"   Para VER os logs do Streamlit, execute: !cat streamlit_log.txt\")\n",
        "    print(\"   Para PARAR TUDO: Interrompa/Reinicie o ambiente de execu√ß√£o do Colab.\")\n",
        "    print(\"=======================================================================\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Erro ao configurar ou iniciar ngrok: {e}\")\n",
        "    print(f\"   Verifique se o token '{NGROK_SECRET_NAME}' est√° nos secrets do Colab.\")\n",
        "    print(f\"   Verifique tamb√©m o log do Streamlit ('streamlit_log.txt') para erros.\")\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDeciCjscU5N",
        "outputId": "93df9735-636e-4cbd-99c0-0cce9b3aac7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Streamlit em Background ---\n",
            "Executando: nohup streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > streamlit_log.txt 2>&1 &\n",
            "Comando para iniciar Streamlit enviado para background.\n",
            "Aguardando alguns segundos para o servidor Streamlit iniciar...\n",
            "\n",
            "Verificando log do Streamlit (streamlit_log.txt)...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.72.62.226:8501\n",
            "\n",
            "\n",
            "--- Configurando Ngrok ---\n",
            "Tentando limpar processos ngrok antigos...\n",
            "Token Ngrok configurado.\n",
            "\n",
            "=======================================================================\n",
            "‚úÖ Aplica√ß√£o Streamlit deve estar rodando em background.\n",
            "   Acesso p√∫blico tempor√°rio via: NgrokTunnel: \"https://9786-34-72-62-226.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "   (Este t√∫nel permanecer√° ativo enquanto esta c√©lula Colab estiver ativa)\n",
            "   Para VER os logs do Streamlit, execute: !cat streamlit_log.txt\n",
            "   Para PARAR TUDO: Interrompa/Reinicie o ambiente de execu√ß√£o do Colab.\n",
            "=======================================================================\n"
          ]
        }
      ]
    }
  ]
}